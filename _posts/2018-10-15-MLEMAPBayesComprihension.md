---
layout: post
title: MLE、MAP、Bayes推断的理解
class: Technology
categories: ["Machine Learning"]
keywords: MLE, MAP, Bayes
---

随着理解的不断加深，对这三个方法又有了本质上的认识。

## **MLE**
MLE是纯Frequencist的思想，与其他最大的区别在于它认为参数$\theta$是一个固定的值。因此可以直接假设观测到的数据分布$P(X|\theta)$是最有可能发生的情况，直接求使其极大的$\theta$作为参数估计。当然也存在期望似然估计等不以极大值为标准的参数估计，但都遵循参数为固定值的思想。

## **MAP**
MAP引入了先验分布，认为$\theta$是一个随机变量。虽然这种思想符合Bayes的思想，但是MAP的目标还是去找到**一个**合适的参数作为模型，只不过考虑了先验知识。所以不好说MAP是B的方法还是F的方法，也没必要太刻意讨论这个问题。再具体说，MAP是去最大化$P(X|\theta)P(\theta)$，$P(\theta)$可以不是分布而是一个“先验知识”，这个式子本身不具备分布的意义，只是借助$P(\theta)$帮助我们去找一个合适的$\theta$，不用去真正的知道$\theta$的概率分布真实值，还是假设X是最有可能发生的情况，据此估计参数。在实际操作中，先验的估计可能只是对比在假设空间中抽得的模型样本即可，不用去算模型的真实分布。

## **贝叶斯推断**
贝叶斯推断是正经Bayes方法，他的目标和前两个的区别在于，我不是去找一个最合适的$\theta$，而是算出模型真正的后验分布$P(\theta|X)$来，通过各种数据分析手段（比如加权求和，极值，均值等）来得到结果。数据只是样本空间中的一个采样。所以要想算出真正的$P(\theta)$，就要去看所有的假设空间，也就是贝叶斯公式分母部分的积分。再放一次贝叶斯公式：

$$
P(\theta|X)=\frac{f(X|\theta)P(\theta)}{\int{f(X|\theta)P(\theta)}d\theta}
$$

这样真实的后验分布就可以算出来了，有了真实后验分布，无论是推断还是数据分析都有了很大的操作空间。对比前面的方法，贝叶斯推断的参数估计因为有了这个积分，所以很难算出来，有以下难点：

 1. 参数分布形式复杂，不容易积分
 2. 参数是高维的向量，多重积分难以计算

容易想到利用蒙特卡洛方法，在假设空间上采样来估计这个分布。然而采样也是一个难点，有些分布没有采样条件。因此，学界提出了很多牛逼的贝叶斯推断的参数估计方法，例如MCMC和Variational Interence等等。

## **参考**
<https://zhuanlan.zhihu.com/p/37215276>
